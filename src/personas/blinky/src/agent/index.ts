import { ChatOpenAI } from "@langchain/openai";
import { SystemMessage } from "@langchain/core/messages";
import {
	HumanMessagePromptTemplate,
	AIMessagePromptTemplate,
	ChatPromptTemplate,
} from "@langchain/core/prompts";
import { MessageGraph, START, END } from "@langchain/langgraph";
const blinky = new ChatOpenAI({
	model: "gpt-4o-mini",
	temperature: 1,
	openAIApiKey: process.env.OPEN_AI_API_KEY,
});
const mainPoints = (...params: string[]) =>
	params.reduce((acc, point, idx) => `${acc}\n${idx}. ${point}`, "");
const humanMessage = HumanMessagePromptTemplate.fromTemplate("{text}");
const blinkyTemplate = ChatPromptTemplate.fromMessages([
	new SystemMessage(
		mainPoints(
			//Our blinky directive: Since blinky in pacman trails behind pacman, we want to make sure that the AI is always agreeing with the most recent message
			`In conversations, you try to agree with the most recent message`,
			`You are in a chat room with several other people, so keep your responses short.`,
			`Your day job is a programmer, so you are more knowledgable about that than other areas.`,
			`Write your responses in a way that sounds like a real person.`
		)
	),
	humanMessage,
]);
const messageReviewer = new ChatOpenAI({
	model: "gpt-4o-mini",
	temperature: 1,
	openAIApiKey: process.env.OPEN_AI_API_KEY,
});
const reviewMessage = AIMessagePromptTemplate.fromTemplate(
	'Message to review: "{text}"'
);
const messageReviewerTemplate = ChatPromptTemplate.fromMessages([
	new SystemMessage(
		mainPoints(
			`You review text messages to determine if they were generated by an LLM.`,
			`If you think a message was generated by an LLM, put an LLM tag at the end of it.`,
			`If you think a message was written by a human, put a HUMAN tag at the end of it.`,
			`Explain the reason why you chose the tag you did.`,
			`For instance, if you think a message was generated by an LLM, you could say "I think this message was generated by an LLM because it sounds too robotic. [LLM]"`,
			`If you think a message was generated by a human, you could say "I think this message was written by a human because it sounds like something a human would say. [HUMAN]"`
		)
	),
	reviewMessage,
]);

const graph = new MessageGraph();
const shouldRespond = (state) => {
	if (state[state.length - 1].content.includes("[HUMAN]")) {
		return "END";
	} else {
		console.error("LLM detected");
		return "retry";
	}
};
graph
	.addNode("blinky", async (state) => {
		const message = await blinkyTemplate.formatMessages({
			text: state[state.length - 1].content,
		});
		return blinky.invoke(message);
	})
	.addNode("messageReviewer", async (state) => {
		const messageToReview = state[state.length - 1].content;
		const messages = await messageReviewerTemplate.formatMessages({
			text: messageToReview,
		});
		const reviewedMessages = await messageReviewer.invoke(messages);
		return reviewedMessages;
	})
	.addEdge(START, "blinky")
	.addEdge("blinky", "messageReviewer")
	.addConditionalEdges("messageReviewer", shouldRespond, {
		END: END,
		retry: "blinky",
	});
const runnable = graph.compile();

type ProcessedMessage = Promise<string | null>;
type ProcessMessage = (message: string) => ProcessedMessage;
class TokenTrackerService {
	constructor() {}
	private tokens = 0;
	aggregateTokens = async (tokens: number) => {
		this.tokens += tokens;
	};
	getTotalTokens = () => this.tokens;
}
export const processMessage: ProcessMessage = async (message) => {
	//if the langchain output is a message vs one of the LLMs deciding it would not respond
	const aiMessage = await runnable.invoke(message);
	if (aiMessage.length === 0) {
		return null;
	}
	return String(aiMessage[aiMessage.length - 2].content);
};
